{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "729159c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc41f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "model=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3916fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the chat history\n",
    "chat_history=[\n",
    "    SystemMessage(content=\"You are a helpful assistant that can answer questions and help with tasks.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f41d571",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "contents are required.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m      9\u001b[39m chat_history.append(HumanMessage(content=user_input))\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m result=model.invoke(chat_history)\n\u001b[32m     11\u001b[39m chat_history.append(AIMessage(content=result.content))\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAlexa:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:2529\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2526\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2527\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2529\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().invoke(\u001b[38;5;28minput\u001b[39m, config, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28mself\u001b[39m.generate_prompt(\n\u001b[32m    399\u001b[39m                 [\u001b[38;5;28mself\u001b[39m._convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[32m    400\u001b[39m                 stop=stop,\n\u001b[32m    401\u001b[39m                 callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    402\u001b[39m                 tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    403\u001b[39m                 metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    404\u001b[39m                 run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    405\u001b[39m                 run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    406\u001b[39m                 **kwargs,\n\u001b[32m    407\u001b[39m             ).generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28mself\u001b[39m._generate_with_cache(\n\u001b[32m    928\u001b[39m                 m,\n\u001b[32m    929\u001b[39m                 stop=stop,\n\u001b[32m    930\u001b[39m                 run_manager=run_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    931\u001b[39m                 **kwargs,\n\u001b[32m    932\u001b[39m             )\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(\n\u001b[32m   1222\u001b[39m         messages, stop=stop, run_manager=run_manager, **kwargs\n\u001b[32m   1223\u001b[39m     )\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:3040\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3027\u001b[39m request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   3028\u001b[39m     messages,\n\u001b[32m   3029\u001b[39m     stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3037\u001b[39m     **kwargs,\n\u001b[32m   3038\u001b[39m )\n\u001b[32m   3039\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3040\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28mself\u001b[39m.client.models.generate_content(\n\u001b[32m   3041\u001b[39m         **request,\n\u001b[32m   3042\u001b[39m     )\n\u001b[32m   3043\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3044\u001b[39m     _handle_client_error(e, request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/google/genai/models.py:5203\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5201\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc > \u001b[32m0\u001b[39m:\n\u001b[32m   5202\u001b[39m   i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5203\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._generate_content(\n\u001b[32m   5204\u001b[39m       model=model, contents=contents, config=parsed_config\n\u001b[32m   5205\u001b[39m   )\n\u001b[32m   5207\u001b[39m   function_map = _extra_utils.get_function_map(parsed_config)\n\u001b[32m   5208\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_map:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/google/genai/models.py:3961\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3959\u001b[39m     path = \u001b[33m'\u001b[39m\u001b[38;5;132;01m{model}\u001b[39;00m\u001b[33m:generateContent\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   3960\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3961\u001b[39m   request_dict = _GenerateContentParameters_to_mldev(\n\u001b[32m   3962\u001b[39m       \u001b[38;5;28mself\u001b[39m._api_client, parameter_model\n\u001b[32m   3963\u001b[39m   )\n\u001b[32m   3964\u001b[39m   request_url_dict = request_dict.get(\u001b[33m'\u001b[39m\u001b[33m_url\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3965\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m request_url_dict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/google/genai/models.py:1304\u001b[39m, in \u001b[36m_GenerateContentParameters_to_mldev\u001b[39m\u001b[34m(api_client, from_object, parent_object)\u001b[39m\n\u001b[32m   1292\u001b[39m   setv(\n\u001b[32m   1293\u001b[39m       to_object,\n\u001b[32m   1294\u001b[39m       [\u001b[33m'\u001b[39m\u001b[33m_url\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   1295\u001b[39m       t.t_model(api_client, getv(from_object, [\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m])),\n\u001b[32m   1296\u001b[39m   )\n\u001b[32m   1298\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m getv(from_object, [\u001b[33m'\u001b[39m\u001b[33mcontents\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1299\u001b[39m   setv(\n\u001b[32m   1300\u001b[39m       to_object,\n\u001b[32m   1301\u001b[39m       [\u001b[33m'\u001b[39m\u001b[33mcontents\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   1302\u001b[39m       [\n\u001b[32m   1303\u001b[39m           _Content_to_mldev(item, to_object)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m           \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m t.t_contents(getv(from_object, [\u001b[33m'\u001b[39m\u001b[33mcontents\u001b[39m\u001b[33m'\u001b[39m]))\n\u001b[32m   1305\u001b[39m       ],\n\u001b[32m   1306\u001b[39m   )\n\u001b[32m   1308\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m getv(from_object, [\u001b[33m'\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1309\u001b[39m   setv(\n\u001b[32m   1310\u001b[39m       to_object,\n\u001b[32m   1311\u001b[39m       [\u001b[33m'\u001b[39m\u001b[33mgenerationConfig\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1314\u001b[39m       ),\n\u001b[32m   1315\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/google/genai/_transformers.py:518\u001b[39m, in \u001b[36mt_contents\u001b[39m\u001b[34m(contents)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mt_contents\u001b[39m(\n\u001b[32m    513\u001b[39m     contents: Optional[\n\u001b[32m    514\u001b[39m         Union[types.ContentListUnion, types.ContentListUnionDict, types.Content]\n\u001b[32m    515\u001b[39m     ],\n\u001b[32m    516\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[types.Content]:\n\u001b[32m    517\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m contents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(contents, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m contents):\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mcontents are required.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    519\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(contents, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [t_content(contents)]\n",
      "\u001b[31mValueError\u001b[39m: contents are required."
     ]
    }
   ],
   "source": [
    "#Invoke and store the chats simultaneously\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input=input(\"You:\")\n",
    "    if user_input.lower()==\"exit\":\n",
    "        break\n",
    "    \n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "    result=model.invoke(chat_history)\n",
    "    chat_history.append(AIMessage(content=result.content))\n",
    "    print(\"Alexa:\")\n",
    "    print(result.content)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Thank you for using the chatbot!\")\n",
    "print(\"Chat History:\", chat_history)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3e08d11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "contents are required.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_input.lower() == \u001b[33m\"\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m result = model.invoke(chat_history)\n\u001b[32m     12\u001b[39m chat_history.append(AIMessage(content=result.content))\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBot:\u001b[39m\u001b[33m\"\u001b[39m, result.content)  \u001b[38;5;66;03m# Display the bot's response\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:2529\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2526\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2527\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2529\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().invoke(\u001b[38;5;28minput\u001b[39m, config, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28mself\u001b[39m.generate_prompt(\n\u001b[32m    399\u001b[39m                 [\u001b[38;5;28mself\u001b[39m._convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[32m    400\u001b[39m                 stop=stop,\n\u001b[32m    401\u001b[39m                 callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    402\u001b[39m                 tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    403\u001b[39m                 metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    404\u001b[39m                 run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    405\u001b[39m                 run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    406\u001b[39m                 **kwargs,\n\u001b[32m    407\u001b[39m             ).generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28mself\u001b[39m._generate_with_cache(\n\u001b[32m    928\u001b[39m                 m,\n\u001b[32m    929\u001b[39m                 stop=stop,\n\u001b[32m    930\u001b[39m                 run_manager=run_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    931\u001b[39m                 **kwargs,\n\u001b[32m    932\u001b[39m             )\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(\n\u001b[32m   1222\u001b[39m         messages, stop=stop, run_manager=run_manager, **kwargs\n\u001b[32m   1223\u001b[39m     )\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:3040\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3027\u001b[39m request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   3028\u001b[39m     messages,\n\u001b[32m   3029\u001b[39m     stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3037\u001b[39m     **kwargs,\n\u001b[32m   3038\u001b[39m )\n\u001b[32m   3039\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3040\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28mself\u001b[39m.client.models.generate_content(\n\u001b[32m   3041\u001b[39m         **request,\n\u001b[32m   3042\u001b[39m     )\n\u001b[32m   3043\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3044\u001b[39m     _handle_client_error(e, request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/google/genai/models.py:5203\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5201\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc > \u001b[32m0\u001b[39m:\n\u001b[32m   5202\u001b[39m   i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5203\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._generate_content(\n\u001b[32m   5204\u001b[39m       model=model, contents=contents, config=parsed_config\n\u001b[32m   5205\u001b[39m   )\n\u001b[32m   5207\u001b[39m   function_map = _extra_utils.get_function_map(parsed_config)\n\u001b[32m   5208\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_map:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/google/genai/models.py:3961\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3959\u001b[39m     path = \u001b[33m'\u001b[39m\u001b[38;5;132;01m{model}\u001b[39;00m\u001b[33m:generateContent\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   3960\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3961\u001b[39m   request_dict = _GenerateContentParameters_to_mldev(\n\u001b[32m   3962\u001b[39m       \u001b[38;5;28mself\u001b[39m._api_client, parameter_model\n\u001b[32m   3963\u001b[39m   )\n\u001b[32m   3964\u001b[39m   request_url_dict = request_dict.get(\u001b[33m'\u001b[39m\u001b[33m_url\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3965\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m request_url_dict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/google/genai/models.py:1304\u001b[39m, in \u001b[36m_GenerateContentParameters_to_mldev\u001b[39m\u001b[34m(api_client, from_object, parent_object)\u001b[39m\n\u001b[32m   1292\u001b[39m   setv(\n\u001b[32m   1293\u001b[39m       to_object,\n\u001b[32m   1294\u001b[39m       [\u001b[33m'\u001b[39m\u001b[33m_url\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   1295\u001b[39m       t.t_model(api_client, getv(from_object, [\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m])),\n\u001b[32m   1296\u001b[39m   )\n\u001b[32m   1298\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m getv(from_object, [\u001b[33m'\u001b[39m\u001b[33mcontents\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1299\u001b[39m   setv(\n\u001b[32m   1300\u001b[39m       to_object,\n\u001b[32m   1301\u001b[39m       [\u001b[33m'\u001b[39m\u001b[33mcontents\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   1302\u001b[39m       [\n\u001b[32m   1303\u001b[39m           _Content_to_mldev(item, to_object)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m           \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m t.t_contents(getv(from_object, [\u001b[33m'\u001b[39m\u001b[33mcontents\u001b[39m\u001b[33m'\u001b[39m]))\n\u001b[32m   1305\u001b[39m       ],\n\u001b[32m   1306\u001b[39m   )\n\u001b[32m   1308\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m getv(from_object, [\u001b[33m'\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1309\u001b[39m   setv(\n\u001b[32m   1310\u001b[39m       to_object,\n\u001b[32m   1311\u001b[39m       [\u001b[33m'\u001b[39m\u001b[33mgenerationConfig\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1314\u001b[39m       ),\n\u001b[32m   1315\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/google/genai/_transformers.py:518\u001b[39m, in \u001b[36mt_contents\u001b[39m\u001b[34m(contents)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mt_contents\u001b[39m(\n\u001b[32m    513\u001b[39m     contents: Optional[\n\u001b[32m    514\u001b[39m         Union[types.ContentListUnion, types.ContentListUnionDict, types.Content]\n\u001b[32m    515\u001b[39m     ],\n\u001b[32m    516\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[types.Content]:\n\u001b[32m    517\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m contents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(contents, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m contents):\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mcontents are required.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    519\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(contents, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [t_content(contents)]\n",
      "\u001b[31mValueError\u001b[39m: contents are required."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "chat_history= [\n",
    "    SystemMessage(content=\"You are a helpful AI assistant.\"),\n",
    "]\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "    result = model.invoke(chat_history)\n",
    "    chat_history.append(AIMessage(content=result.content))\n",
    "    print(\"Bot:\", result.content)  # Display the bot's response\n",
    "\n",
    "print(\"Chat history:\", chat_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73813aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
