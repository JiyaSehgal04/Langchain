{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54549514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb7dfa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='c70093c0-3a8e-4775-a05a-7af88cd49773', metadata={'source': 'chroma_db.txt', 'id': 3, 'topic': 'Vector databases'}, page_content='\\nChroma is an open-source vector database optimized for storing and\\nquerying embeddings. It supports persistence, metadata filtering,\\nand fast similarity search for AI applications.\\n'), Document(id='0756ccdd-81ce-40df-ad6c-4a8cc49687ff', metadata={'topic': 'LLM frameworks', 'id': 1, 'source': 'langchain_intro.txt'}, page_content='\\nLangChain is a framework designed to help developers build applications\\npowered by large language models (LLMs). It provides abstractions for\\nprompt management, chains, agents, memory, and integrations with\\nvector databases.\\n'), Document(id='9d55ade0-80c9-471e-bc2f-0f59626cd306', metadata={'topic': 'RAG', 'id': 2, 'source': 'rag_overview.txt'}, page_content='\\nRetrieval-Augmented Generation (RAG) combines information retrieval\\nwith text generation. Relevant documents are retrieved from a vector\\ndatabase and passed as context to an LLM to produce grounded answers.\\n')]\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "embeddings=HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    ")\n",
    "doc1 = Document(\n",
    "    page_content=\"\"\"\n",
    "LangChain is a framework designed to help developers build applications\n",
    "powered by large language models (LLMs). It provides abstractions for\n",
    "prompt management, chains, agents, memory, and integrations with\n",
    "vector databases.\n",
    "\"\"\",\n",
    "    metadata={\n",
    "        \"source\": \"langchain_intro.txt\",\n",
    "        \"topic\": \"LLM frameworks\",\n",
    "        \"id\": 1\n",
    "    }\n",
    ")\n",
    "\n",
    "doc2 = Document(\n",
    "    page_content=\"\"\"\n",
    "Retrieval-Augmented Generation (RAG) combines information retrieval\n",
    "with text generation. Relevant documents are retrieved from a vector\n",
    "database and passed as context to an LLM to produce grounded answers.\n",
    "\"\"\",\n",
    "    metadata={\n",
    "        \"source\": \"rag_overview.txt\",\n",
    "        \"topic\": \"RAG\",\n",
    "        \"id\": 2\n",
    "    }\n",
    ")\n",
    "\n",
    "doc3 = Document(\n",
    "    page_content=\"\"\"\n",
    "Chroma is an open-source vector database optimized for storing and\n",
    "querying embeddings. It supports persistence, metadata filtering,\n",
    "and fast similarity search for AI applications.\n",
    "\"\"\",\n",
    "    metadata={\n",
    "        \"source\": \"chroma_db.txt\",\n",
    "        \"topic\": \"Vector databases\",\n",
    "        \"id\": 3\n",
    "    }\n",
    ")\n",
    "\n",
    "doc4 = Document(\n",
    "    page_content=\"\"\"\n",
    "Embeddings convert text into dense numerical vectors that capture\n",
    "semantic meaning. These vectors enable similarity search, clustering,\n",
    "and recommendation systems.\n",
    "\"\"\",\n",
    "    metadata={\n",
    "        \"source\": \"embeddings.txt\",\n",
    "        \"topic\": \"Embeddings\",\n",
    "        \"id\": 4\n",
    "    }\n",
    ")\n",
    "\n",
    "doc5 = Document(\n",
    "    page_content=\"\"\"\n",
    "Python is widely used in AI and data science due to its simplicity,\n",
    "rich ecosystem of libraries, and strong community support.\n",
    "\"\"\",\n",
    "    metadata={\n",
    "        \"source\": \"python_ai.txt\",\n",
    "        \"topic\": \"Programming language\",\n",
    "        \"id\": 5\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "docs=[doc1,doc2,doc3,doc4,doc5]\n",
    "\n",
    "\n",
    "vector_store=Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"chroma_db\",\n",
    "    collection_name=\"sample\"\n",
    ")\n",
    "\n",
    "vector_store.add_documents(docs)\n",
    "vector_store.get(include=[\"documents\",\"metadatas\",\"embeddings\"])\n",
    "\n",
    "\n",
    "query=\"Who among there are the best players in the world?\"\n",
    "result=vector_store.similarity_search(\n",
    "    query=query,\n",
    "    k=3\n",
    ")\n",
    "\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n",
    "result=vector_store.similarity_search_with_score(\n",
    "    query=query,\n",
    "    k=3\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac94f90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the hugging face embeddings\n",
    "#create a list of the docs\n",
    "#Define the vector store embedding_function, the persist_directory and collection_name\n",
    "#create the vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d01044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437078ce",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
